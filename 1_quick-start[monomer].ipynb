{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: AlphaFold Inference with Vertex Pipelines [Monomer]\n",
    "\n",
    "This quick start notebook demonstrates how to configure and run the Universal inference pipeline using the monomer presets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U kfp google-cloud-aiplatform google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from kfp.v2 import compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure environment settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the values of the following parameters to reflect your environment.\n",
    "\n",
    "- `PROJECT` - Project ID of your environment\n",
    "- `REGION`- GCP Region where your resources are located\n",
    "- `BUCKET_NAME` - GCS bucket to use for Vertex staging. Must be located in the `REGION`\n",
    "- `FILESTORE_IP` - IP address of your Filestore instance\n",
    "- `FILESTORE_NETWORK_NAME` - Filestore VPC name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = '<YOUR PROJECT ID>'  # Change to your project ID\n",
    "REGION = '<YOUR REGION>'   # Change to your region\n",
    "BUCKET_NAME = '<YOUR BUCKET NAME>'  # Change to your bucket name        \n",
    "FILESTORE_IP = '<FILESTORE IP ADDREDD>' # Change the IP of your Filestore instance\n",
    "FILESTORE_NETWORK_NAME = '<FILESTORE NETWORK NAME>' # Change to the name of the Filestore instance network name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you set up the sandbox environment using the provided Terraform configuration you do not need to change the below settings. Otherwise make sure that they are consistent with your environment.\n",
    "\n",
    "- `FILESTORE_SHARE` - Filestore share with AlphaFold reference databases\n",
    "- `FILESTORE_MOUNT_PATH` - Mount path for Filestore fileshare\n",
    "- `MODEL_PARAMS` - GCS location of AlphaFold model parameters. The pipelines are configured to retrieve the parameters from the `<MODEL_PARAMS>/params` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILESTORE_SHARE = '/datasets'\n",
    "FILESTORE_MOUNT_PATH = '/mnt/nfs/alphafold'\n",
    "PROJECT_NUMBER = !(gcloud projects list --filter=\"projectId:{PROJECT}\" --format=\"value(PROJECT_NUMBER)\")  \n",
    "FILESTORE_NETWORK = f'projects/{PROJECT_NUMBER[0]}/global/networks/{FILESTORE_NETWORK_NAME}'  \n",
    "MODEL_PARAMS = f'gs://{BUCKET_NAME}'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT}/alphafold-components'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and run the Universal pipeline with monomer presets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of parameters that can be used to customize Vertex Pipelines: compile time and runtime. The compile time parameters must be set before compiling the pipeline code. The runtime parameters can be supplied when starting a pipeline run.\n",
    "\n",
    "In the AlphaFold inference pipelines, the compile time parameters are used to control settings like CPU/GPU configuration of compute nodes and the Filestore instance settings. The runtime parameters include a sequence to fold, model presets, the maximum date for template searches and more. \n",
    "\n",
    "The pipelines have been designed to retrieve compile time parameters from environment variables. This makes it easy to integrate a pipeline compilation step with CI/CD systems.\n",
    "\n",
    "By default, the pipeline uses a `c2-standard-16` node to run the feature engineering step and  `n1-standard-8` nodes with NVIDIA T4 GPUs to run prediction and relaxation. For now, you will use the default settings. This hardware configuration is optimal for folding smaller proteins, roughly 1000 residues or fewer. \n",
    "\n",
    "In other notebooks we will demonstrate how to change the default hardware configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set compile time parameters\n",
    "\n",
    "At minimum you have to configure:\n",
    "- the settings of your Filestore instance that hosts genetic databases, \n",
    "- the URI of the docker image that packages custom KFP components, and \n",
    "- the GCS location of AlphaFold parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ALPHAFOLD_COMPONENTS_IMAGE'] = IMAGE_URI\n",
    "os.environ['NFS_SERVER'] = FILESTORE_IP\n",
    "os.environ['NFS_PATH'] = FILESTORE_SHARE\n",
    "os.environ['NETWORK'] = FILESTORE_NETWORK\n",
    "os.environ['MODEL_PARAMS_GCS_LOCATION'] = MODEL_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines.alphafold_inference_pipeline import alphafold_inference_pipeline as pipeline\n",
    "\n",
    "pipeline_name = 'universal-pipeline'\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=f'{pipeline_name}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure runtime parameters\n",
    "\n",
    "At minimum you need to configure a GCS location of your sequence, the maximum date for template searches and a project and region where to run the pipeline. With the default settings, the pipeline will run monomer inference using the small version of BFD.\n",
    "\n",
    "#### Copy the sample sequence to a GCS location\n",
    "\n",
    "You can find a few sample sequences in the `sequences` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'T1050.fasta'\n",
    "gcs_sequence_path = f'gs://{BUCKET_NAME}/fasta/{sequence}'\n",
    "\n",
    "! gsutil cp sequences/{sequence} {gcs_sequence_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'sequence_path': gcs_sequence_path,\n",
    "    'max_template_date': '2020-05-14',\n",
    "    'model_preset': 'monomer',\n",
    "    'project': PROJECT,\n",
    "    'region': REGION,\n",
    "    'is_run_relax': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a pipeline run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend annotating pipeline runs with at least two labels. The first label groups multiple pipeline runs into a single experiment. The second label identifies a given run within the experiment. Annotating with labels helps to discover and analyze pipeline runs in large scale settings. The third notebook that demonstrates how to analyze pipeline runs depends on the labels. \n",
    "\n",
    "You will be able to monitor the run using the link printed by executing the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = 'T1050-experiment'\n",
    "labels = {'experiment_id': experiment_id.lower(), 'sequence_id': sequence.split(sep='.')[0].lower()}\n",
    "\n",
    "pipeline_job = vertex_ai.PipelineJob(\n",
    "    display_name=pipeline_name,\n",
    "    template_path=f'{pipeline_name}.json',\n",
    "    pipeline_root=f'gs://{BUCKET_NAME}/pipeline_runs/{pipeline_name}',\n",
    "    parameter_values=params,\n",
    "    enable_caching=False,\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "pipeline_job.run(sync=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the state of the pipeline\n",
    "pipeline_job.state"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m92",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m92"
  },
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
